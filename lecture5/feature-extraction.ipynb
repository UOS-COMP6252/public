{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/UOS-COMP6252/public/blob/main/lecture5/conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolution Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTsa4o4TAkhT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as vision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD,Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolution Network for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# select the device \n",
    "#to ensure some reproducibility \n",
    "seed=9 \n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "dataset_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=transform)\n",
    "dataset_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=transform)\n",
    "loader_train=DataLoader(dataset_train,batch_size=64,shuffle=True,num_workers=2)\n",
    "loader_test=DataLoader(dataset_test,batch_size=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # input is (*,3,32,32)\n",
    "    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
    "    self.relu=nn.ReLU()\n",
    "    # input is (*,32,30,30)\n",
    "    self.conv2=nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
    "    # input is (*,32,28,28)\n",
    "    self.pool1=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,32,14,14)\n",
    "    self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,12,12)\n",
    "    self.conv4=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,10,10)\n",
    "    self.pool2=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,64,5,5)\n",
    "    self.flatten=nn.Flatten()\n",
    "    # input is (*,64x5x5)\n",
    "    self.fc1=nn.Linear(in_features=5*5*64,out_features=128)\n",
    "    self.fc2=nn.Linear(in_features=128,out_features=10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.conv2(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool1(x)\n",
    "    \n",
    "    x=self.conv3(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.conv4(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool2(x)\n",
    "    \n",
    "    x=self.flatten(x)\n",
    "    x=self.fc1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.fc2(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader,model,device):\n",
    "  total=len(dataloader.dataset.data)\n",
    "  correct=0\n",
    "  for data in dataloader:\n",
    "    imgs,labels=data\n",
    "    imgs=imgs.to(device)\n",
    "    labels=labels.to(device)\n",
    "    outputs=model(imgs)\n",
    "  # the second return value is the index of the max i.e. argmax\n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    correct+=(predicted==labels).sum()\n",
    "  \n",
    "\n",
    "  return (correct/total).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model=Net().to(device)\n",
    "optimizer=Adam(model.parameters())\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  loop=tqdm(loader_train)\n",
    "  loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "  epoch_loss=0.\n",
    "  for (imgs,labels) in loop:\n",
    "    optimizer.zero_grad()\n",
    "    imgs=imgs.to(device)\n",
    "    labels=labels.to(device)\n",
    "    outputs=model(imgs)\n",
    "    loss=loss_fn(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss=0.9*epoch_loss+0.1*loss.item()\n",
    "    loop.set_postfix(loss=epoch_loss)\n",
    "  t_acc=get_accuracy(loader_train,model,device) \n",
    "  v_acc=get_accuracy(loader_test,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "   from torchmetrics import ConfusionMatrix\n",
    "except: \n",
    "    !pip install torchmetrics\n",
    "    from torchmetrics import ConfusionMatrix\n",
    "\n",
    "conmat=ConfusionMatrix(task='multiclass',num_classes=10)\n",
    "conmat=conmat.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "total=0\n",
    "correct=0\n",
    "for data in loader_test:\n",
    "  imgs,labels=data\n",
    "  imgs=imgs.to(device)\n",
    "  labels=labels.to(device)\n",
    "  outputs=model(imgs)\n",
    "  # the second return value is the index of the max i.e. argmax\n",
    "  _,predicted=torch.max(outputs.data,1)\n",
    "  correct+=(predicted==labels).sum()\n",
    "  total+=labels.size()[0]\n",
    "  conmat.update(predicted,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "x=conmat.compute().cpu().numpy()\n",
    "plt.figure(figsize=(10,7))\n",
    "sb.heatmap(x,xticklabels=dataset_train.classes,yticklabels=dataset_train.classes,annot=True,fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import get_graph_node_names,create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=get_graph_node_names(model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes={'conv1':'layer1','conv2':'layer2','conv3':'layer3','conv4':'layer4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=create_feature_extractor(model,return_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Description](image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(activation):\n",
    "    n_row = 8\n",
    "    n_column = activation.shape[-1]//n_row\n",
    "    \n",
    "    f, ax = plt.subplots(n_row, n_column)\n",
    "    for i in range(n_row):\n",
    "        for j in range(n_column):\n",
    "            channel_image = activation[:, :, i*n_column+j]\n",
    "            # image post-processing for better visualization\n",
    "            # channel_image -= channel_image.mean()\n",
    "            # channel_image /= channel_image.std()\n",
    "            channel_image *= 255\n",
    "            #channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "        \n",
    "            #ax[i, j].imshow(channel_image, cmap='viridis')\n",
    "            #ax[i, j].imshow(channel_image, cmap='coolwarm')\n",
    "            #ax[i, j].imshow(channel_image, cmap='Greys')\n",
    "            ax[i, j].imshow(channel_image, cmap='bwr')\n",
    "            #ax[i, j].imshow(channel_image, cmap='inferno')\n",
    "            #ax[i, j].imshow(channel_image, cmap='copper')\n",
    "            ax[i, j].axis('off')\n",
    "            ax[i, j].set_xticklabels([])\n",
    "            ax[i, j].set_yticklabels([])\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    f.set_size_inches(n_column, n_row)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr=iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while labels[0].item()!=0:\n",
    "    imgs,labels=next(itr)   \n",
    "imgs=imgs.to(device)\n",
    "with torch.no_grad():\n",
    "    output=f(imgs)\n",
    "a=output['layer3'][0].cpu().numpy().transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "seq=[]\n",
    "while n!=32:\n",
    "    imgs,labels=next(itr)   \n",
    "    if labels[0].item()==0:\n",
    "        n+=1\n",
    "        imgs=imgs.to(device)\n",
    "        with torch.no_grad():\n",
    "            output=f(imgs)\n",
    "            a=output['layer3'][0].cpu().numpy().transpose(1,2,0)\n",
    "            b=a.sum(axis=2)\n",
    "            seq.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for b in seq:\n",
    "    plt.imshow(b)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=imgs[0].cpu().numpy().transpose(1,2,0)\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "#plt.imshow(rgb2gray(img),cmap='gray_r')\n",
    "plt.imshow(img)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "list(colormaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
