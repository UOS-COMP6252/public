{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/dl_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXG2Gc34Vqio",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What you will learn in this notebook\n",
    " \n",
    "1. PyTorch tensors and operations on them\n",
    "1. PyTorch autograd and backward method\n",
    "1. PyTorch packages autograd, torchvision, datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PyTorch Tensors\n",
    "- A PyTorch ```tensor``` is an object that stores a multidimensional array\n",
    "- A ```tensor``` according to [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html) is a multidimensional matrix containing elements of a single data type.\n",
    "- In addition to the data, a tensor has a large number of attributes and functions\n",
    "- A PyTorch tensor has a similar interface to numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# a 2-dim tensor created from a list of lists\n",
    "b=torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)\n",
    "print(\"b={}\".format(b))\n",
    "print(\"b has dimensions {}\".format(b.shape))\n",
    "#torch.Size() is iterable so we can create a list or tuple\n",
    "print(\"b has dimensions {}\".format(tuple(b.shape)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# A 0-dim tensor. Without dtype it will be implicitly an integer\n",
    "a=torch.tensor(1,dtype=torch.float32)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "# use .item() to extract a scalar from a 0-d tensor\n",
    "print(\"single value in a is {}\".format(a.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensor slices\n",
    "- Indexing and slices are similar to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(b)\n",
    "print(tuple(b.size()))\n",
    "#print row index 0\n",
    "print(b[0,:])\n",
    "#print column index 1\n",
    "print(b[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given b below. What is the output of ```print(b[:,0:2])```? Use Vevox ID 159-794-831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(b[:,[0,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. $$\\begin{bmatrix} 7 & 8 \\\\ 10 &11 \\end{bmatrix}$$\n",
    "1. $$\\begin{bmatrix} 7 & 9 \\\\ 10 & 12 \\end{bmatrix}$$\n",
    "1. $$\\begin{bmatrix} 8 & 9\\\\ 11& 12 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From/to numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([[1,2,3],[4,5,6]],dtype=np.float32)### squeeze/unsqueeze/stack\n",
    "b=torch.from_numpy(a)\n",
    "print(\"b={}\".format(b))\n",
    "print(\"b has {} as data type\".format(b.dtype))\n",
    "print(\"convert b to numpy array\")\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful PyTorch operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a tensor of shape (2,3) whose values are all zeros \n",
    "a=torch.zeros([2,3])\n",
    "print(a)\n",
    "# Same as above but filled with ones\n",
    "a=torch.ones([3,2])\n",
    "print(a)\n",
    "# Same as above but filled with random values from a uniform distribution over [0,1] \n",
    "# https://pytorch.org/docs/stable/generated/torch.rand.html\n",
    "a=torch.rand([2,3])\n",
    "# See also randn for a normal distribution\n",
    "#https://pytorch.org/docs/stable/generated/torch.randn.html\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful operations for creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A tensor filled with ones that has the same dimensions as tensor a\n",
    "b=torch.ones_like(a)\n",
    "print(b)\n",
    "\n",
    "# Transpose a tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"transpose of a=\")\n",
    "print(a.transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Operations that change the shape of tensors\n",
    "- In some situations one might need to add/remove dimensions from a tensor\n",
    "- This can only be done if added/removed dimensionality size is one\n",
    "- For example, a tensor of shape (1,3,3) or (2,1,2)\n",
    "- Can be converted to (3,3) and (2,2)\n",
    "- and vice-versa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### squeeze/unsqueeze/reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2,3],[4.,5.,6.]])\n",
    "print(\"a's shape\",tuple(a.size()))\n",
    "b=a.unsqueeze(0)\n",
    "print(\"b's shape\",tuple(b.size()))\n",
    "c=a.unsqueeze(0).unsqueeze(2)\n",
    "print(\"c's shape\",tuple(c.size()))\n",
    "d=c.squeeze()\n",
    "print(\"d's shape\", tuple(d.size()))\n",
    "a.reshape(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### stack/flatten/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.tensor([1.,2,3])\n",
    "b=torch.tensor([4,5.,6])\n",
    "c=torch.stack((a,b))\n",
    "print(\"c=\",c)\n",
    "d=torch.stack([a,b],dim=1)\n",
    "print(\"d=\",d)\n",
    "print(\"d flattened=\",d.flatten())\n",
    "e=torch.stack([c,c])\n",
    "print(\"e's shape is \",tuple(e.size()))\n",
    "## view is used often in PyTorch models\n",
    "e=e.view(e.size()[0],-1)\n",
    "print(\"e's shape is \",tuple(e.size()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In-place tensor operations\n",
    "\n",
    "- Given a tensor A\n",
    "- Some operations on A create a copy of A\n",
    "- Some operations (in-place) modify the tensor A itself. Usually have a \"_\" suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)\n",
    "print(a.shape)\n",
    "a.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a.unsqueeze_(0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([[7,8,9],[10,11,12]])\n",
    "c=torch.stack([a,b],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(c[:,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Answer on Vevox with ID 159-794-831\n",
    "1. $$\\begin{bmatrix} 1 & 2 &3\\\\ 4 &5 &6 \\end{bmatrix}$$\n",
    "1. $$\\begin{bmatrix} 1 & 2 &3\\\\ 7& 8 & 9 \\end{bmatrix}$$\n",
    "1. $$\\begin{bmatrix} 1 & 4 & 7\\\\ 2& 5& 8 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More about in-place operations\n",
    "- In addition to methods with an underscore suffix the following are also in-place\n",
    "- +=,-=,*=,/=,\n",
    "- using an index or slice, e.g. x[0]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x=torch.tensor([1.,2])\n",
    "y=torch.tensor([3.,4])\n",
    "print(id(x))\n",
    "x=x+y # a new tensor is allocated\n",
    "print(id(x))\n",
    "x+=y # this is an in-place operation\n",
    "print(id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x=torch.tensor([1.,2])\n",
    "y=torch.tensor([3.,4])\n",
    "x=x+y # a new tensor is allocated\n",
    "x+=y # this is an in-place operation\n",
    "print(id(x))\n",
    "x[0]=9\n",
    "print(id(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autograd package\n",
    "\n",
    "- Deep learning involves optimization that require the computation of gradients\n",
    "- An example was the linear regression discussed previously \n",
    "- Using PyTorch's Autograd package one can automatically differentiate any function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "x=torch.tensor(3.,requires_grad=True)\n",
    "y=torch.tensor(2.,requires_grad=True)\n",
    "z=x**2+4*y\n",
    "r=grad(z,[x,y])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using ```.backward()```\n",
    "\n",
    "- An alternative may is to use the ```tensor.backward()``` method\n",
    "- Unlike ```grad``` it does not return the gradients but **saves** them in ```.grad``` attribute of the dependent tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(3.,requires_grad=True)\n",
    "y=torch.tensor(2.,requires_grad=True)\n",
    "z=x**2+4*y\n",
    "z.backward()\n",
    "print(x.grad,y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpJEiPpbHjjk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTorch Dataset\n",
    "- PyTorch has many built-in datasets \n",
    "- They are all subclasses of ```torch.utils.data.Datasets```\n",
    "- A subset of those datasets can be access in the ```torchvision.datasets```\n",
    "- In the following example we will use the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In most deep learning problem one needs a training dataset to train the model\n",
    "- And a test dataset to gauge how well the trained model generalizes to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "9daf573e127d45b0a13d392d625f6dd7",
      "df2a9b2f02d2434682d4ca213568fbc9",
      "ffce6ae3a0f14491a4690ddec0df4674",
      "716eed7ac5b242b1a43d095c0376fdfd",
      "10a2f8fa1176415eb1427954d02ac81e",
      "fc2f840078b44934a9a0a972b2d1a6aa",
      "c49c0f939d094f8bb00e028bcae134cb",
      "c25206d0d8be44e3b18028c61228dbd4",
      "1fe3e0a792204b568fdeada38bff559a",
      "eff7dac6203a4409bd25e5a0fafbfe5f",
      "ffe956b562a148a9abb63f496ce91030"
     ]
    },
    "id": "XXoGGW1OaAEZ",
    "outputId": "7ca064b1-c917-42e1-e5ed-88e7e00311ca",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision as vision\n",
    "# train=True is the default\n",
    "cifar10_train=vision.datasets.CIFAR10(\".\",download=True,train=True)\n",
    "cifar10_test=vision.datasets.CIFAR10(\".\",download=True,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiK2f9uyH2uH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring the dataset\n",
    "- Almost always it helps to get an idea of the properties of the dataset\n",
    "- For example, how many items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tHVh-P7IQ8h",
    "outputId": "e81acc7a-69ad-4dde-8941-f7940d9c89eb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_samples=len(cifar10_train)\n",
    "test_samples=len(cifar10_test)\n",
    "print(\"The length of training data is {} and the test data is {}\".format(train_samples,test_samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Classification datasets\n",
    "- \"raw\" values are in ```dataset.data``` and ```dataset.targets```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(cifar10_train.targets)\n",
    "print(\"data type={}, targets type={}\".format(type(cifar10_train.data),type(cifar10_train.targets)))\n",
    "print(\"possible targets values:\")\n",
    "np.unique(cifar10_train.targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datasets are subscriptable\n",
    "\n",
    "- One can access invidual data elements using the subscript operator\n",
    "- Note that an \"element\" is a tuple (pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "item=cifar10_train[0]\n",
    "img=item[0]\n",
    "label=item[1]\n",
    "print(type(img),type(label))\n",
    "# a more concise way\n",
    "img,label=item\n",
    "print(type(img),type(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7zBqVB3oCeV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Iterating over a dataset\n",
    "- Because datasets are **iterable** objects (see explanation [here](https://docs.python.org/3/glossary.html) ) the best way to explore the items is through an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JziiKBlKnDqH",
    "outputId": "e3603c30-1504-430c-b021-6e9732b0d4b6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create an iterator to the dataset\n",
    "itr=iter(cifar10_train)\n",
    "#fetch the next item\n",
    "item =next(itr)\n",
    "print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img,label=item\n",
    "print(\"First element has type={}, second has type={}\".format(type(img),type(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can one iterate over the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "itr=iter(cifar10_train)\n",
    "count=0\n",
    "while True:\n",
    "    try:\n",
    "        img,label=next(itr)\n",
    "        count+=1\n",
    "    except StopIteration:\n",
    "        break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### for loop to the rescue\n",
    "- That was the \"low level\" way of iteration over an **iterable**\n",
    "- Python provides a \"for\" construct that hides those details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for item  in cifar10_train:\n",
    "    img,label=item\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "EuyZNWfIJmml",
    "outputId": "b9e32003-ec04-4ef0-ce82-def96a49f5c5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the first image (a frog) and set the corresponding label as title\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.set_size_inches(1.5,1.5)\n",
    "p=fig.add_subplot()\n",
    "\n",
    "p.set_title(str(label))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyNuNqO6ce7qryqS+HxdL/2J",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10a2f8fa1176415eb1427954d02ac81e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fe3e0a792204b568fdeada38bff559a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "716eed7ac5b242b1a43d095c0376fdfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff7dac6203a4409bd25e5a0fafbfe5f",
      "placeholder": "​",
      "style": "IPY_MODEL_ffe956b562a148a9abb63f496ce91030",
      "value": " 170498071/170498071 [00:02&lt;00:00, 73485295.02it/s]"
     }
    },
    "9daf573e127d45b0a13d392d625f6dd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df2a9b2f02d2434682d4ca213568fbc9",
       "IPY_MODEL_ffce6ae3a0f14491a4690ddec0df4674",
       "IPY_MODEL_716eed7ac5b242b1a43d095c0376fdfd"
      ],
      "layout": "IPY_MODEL_10a2f8fa1176415eb1427954d02ac81e"
     }
    },
    "c25206d0d8be44e3b18028c61228dbd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c49c0f939d094f8bb00e028bcae134cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df2a9b2f02d2434682d4ca213568fbc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc2f840078b44934a9a0a972b2d1a6aa",
      "placeholder": "​",
      "style": "IPY_MODEL_c49c0f939d094f8bb00e028bcae134cb",
      "value": "100%"
     }
    },
    "eff7dac6203a4409bd25e5a0fafbfe5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2f840078b44934a9a0a972b2d1a6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffce6ae3a0f14491a4690ddec0df4674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c25206d0d8be44e3b18028c61228dbd4",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fe3e0a792204b568fdeada38bff559a",
      "value": 170498071
     }
    },
    "ffe956b562a148a9abb63f496ce91030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
