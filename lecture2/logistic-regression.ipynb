{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/UOS-COMP6252/public/blob/main/lecture2/logistic-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">COMP6252 Deep Learning Technologies</h1>\n",
    "<h2 style=\"text-align: center;\"> Lecture 2</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXG2Gc34Vqio",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What you will learn in this notebook\n",
    " \n",
    "1. Explain stochastic gradient descent\n",
    "1. Apply PyTorch DataLoader\n",
    "1. Use logistic regression for binary classification\n",
    "1. Implement a binary classifier in PyTorch \n",
    "2. Use Comet platform to log results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will be using comet_ml to log our experiments\n",
    "import comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpJEiPpbHjjk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CIFAR10 Dataset\n",
    "\n",
    "- We use the CIFAR10 dataset to perform binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j6mq7QsZzsF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision as vision\n",
    "\n",
    "cifar10_train=vision.datasets.CIFAR10(\".\",download=True,train=True)# train=True is the default\n",
    "cifar10_test=vision.datasets.CIFAR10(\".\",download=True,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first image (a frog) and set the corresponding label as title\n",
    "img0,label0=cifar10_train[0]\n",
    "print(type(img0))\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.set_size_inches(1,1)\n",
    "p=fig.add_subplot()\n",
    "\n",
    "p.set_title(str(label0))\n",
    "p.axes.get_xaxis().set_visible(False)\n",
    "p.axes.get_yaxis().set_visible(False)\n",
    "plt.imshow(img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7zBqVB3oCeV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data transforms\n",
    "- Recall from last session that CIFAR10 contains a set of images/labels. To use the dataset with PyTorch we need to **transform** the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JziiKBlKnDqH",
    "outputId": "e3603c30-1504-430c-b021-6e9732b0d4b6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image,label=cifar10_train[0]\n",
    "print(type(image),type(label))\n",
    "print(type(image),type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "cifar10_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=ToTensor())\n",
    "cifar10_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=ToTensor())\n",
    "img,label=cifar10_train[0]\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary classification\n",
    "\n",
    "- The dataset has 10 classes: Airplanes,Cars,Birds,Cats,Deers,Dogs,Frogs,Horses, Ships and Trucks\n",
    "- For simplicity we will rearrange it into only 2 classes\n",
    "    - Animate: Birds, Cats,Deers,Dogs, Frogs, Horses\n",
    "    - Inanimate: Airplanes, Cars, Ships and Trucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Rearrange both the train and test datasets\n",
    "- Why didn't we use ```label=1``` and ```label=0``` in the code below ?\n",
    "- Use Vevox session 131-699-292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#airplane=0,car=1,bird=2,cat=3,deer=4,dog=5,frog=6,horse=7,ship=8,truck=9\n",
    "features=torch.tensor([0,1,8,9])\n",
    "for i, (img,label) in enumerate(cifar10_train):\n",
    "    if torch.isin(label,features):\n",
    "        cifar10_train.targets[i]=1\n",
    "    else:\n",
    "        cifar10_train.targets[i]=0\n",
    "for i, (img,label) in enumerate(cifar10_test):\n",
    "    if torch.isin(label,features):\n",
    "        cifar10_test.targets[i]=1\n",
    "    else:\n",
    "        cifar10_test.targets[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "- So far the gradient was computed over the whole dataset\n",
    "    - In many situations this is not feasible, e.g. not enough memory\n",
    "- A good approximation is **stochastic** gradient descent\n",
    "    - The gradient is computed for a single sample\n",
    "- Another, most commonly used variant, is to compute the gradient over a random subset of the dataset **(batch)**\n",
    "    - Saves memory\n",
    "    - Better chance to escape local minima\n",
    "    - Usually called **mini batch** GD\n",
    "- Another advantage of SGD is it helps us get out of local minima\n",
    "- Henceforth, when we say GD or SGD we mean mini batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data loader\n",
    "- SGD is more efficient when the batches are randomly selected\n",
    "- PyTorch provides a convenient class for operations on batches: ```DataLoader```\n",
    "- ```num_workers``` is the number of threads used for parallel processing\n",
    "- ```shuffle=True``` means the dataset is randomly shuffled after a complete pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=64\n",
    "train_loader=DataLoader(cifar10_train,shuffle=True,batch_size=batch_size,num_workers=2)\n",
    "test_loader=DataLoader(cifar10_test,batch_size=batch_size,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that the images have 3 channels and are 32x32. The batch size=64\n",
    "- What is the shape of **imgs** and **labels** in the code below?\n",
    "- Use Vevox session 131-699-292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "itr=iter(train_loader)\n",
    "imgs,labels=next(itr)\n",
    "print(imgs.size(),labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4udcJFDWf8-8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "- Logistic Regression can be regarded as the **simplest neural network**, a single \"neuron\". \n",
    "- It takes as input a vector of size $n$ and it feeds a single unit (a neuron or perceptron). \n",
    "- The neuron is represented by a vector of **learnable** weights $w$ and bias $b$\n",
    "- The output is the sum of $b$ and the **dot** product between $w$ and the vector input $x$\n",
    "- The result is fed into some function (usually nonlinear) $f$ called the activation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z&=\\sum_iw_i\\cdot x_i+b\\\\\n",
    "\\hat{y}(x)&=f(z)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- Note that because $z$ depends on $W$ and $b$ so does $\\hat{y}$. \n",
    "- Therefore our task is to **learn** the \"best\" values of $W$ and $b$ to model the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The input $x$ and $f$ are **known** whereas $w$ and $b$ are **parameters** to be determined. \n",
    "- Our goal is to find the _optimal_ $w$ and $b$ such that the output is as *close as possible* to the label associated with the input.\n",
    "\n",
    "![perceptron.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- How is \"**as close as possible**\" defined? \n",
    "- The dataset is usually a set of pairs $(x,y)$. \n",
    "- We define the loss as the **deviation** between the label $y$ and the result $\\hat{y}=f(z)$\n",
    "\n",
    "$$loss=\\mathcal{L}_{w,b}(y,\\hat{y})$$\n",
    "\n",
    "- The function $\\mathcal{L}$ depends on the problem (for example binary cross entropy, mean squared error,...)\n",
    "\n",
    "- Note that $\\mathcal{L}$ depends on the parameters $w,b$. \n",
    "- Our goal is to find the **optimal** $w,b$ such that $\\mathcal{L}$ is minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wha5x_KeRHkw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigmoid\n",
    "\n",
    "- So far we have not specified the function _f_ that our  model depends on $\\hat{y}=f(z)$. \n",
    "- In this example we use the **sigmoid** function. Given an input _z_ it has the form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma=\\frac{1}{1+e^{-z}}\n",
    "\\end{align*}\n",
    "$$\n",
    "- The values of $\\sigma$ go from 0 to 1 which we interpret as the probability that the label is 1\n",
    "- $1-\\sigma$ is the probability that the label is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "wAe6yJrBRN_1",
    "outputId": "7bd84e2d-f3f9-44e0-f6b9-d6565aaff745",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "z=[1/(1+np.exp(-x)) for x in range(-10,11)]\n",
    "plt.plot([x for x in range(-10,11)],z)\n",
    "plt.xticks([t for t in range(-10,11,2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vMc-jV9pIcd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Flattening the images\n",
    "- The input images have dimensions (3,32,32) (3 channels, 32 height,32 width). \n",
    "- To use them as input to the \"neuron\" we need to \"flatten\" the input\n",
    "- One can use the ```.reshape``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvukYwIicPqx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "itr=iter(train_loader)\n",
    "imgs,labels=next(itr)\n",
    "imgs=imgs.reshape(batch_size,-1)\n",
    "print(imgs.shape,labels.shape)\n",
    "torch.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- One can use ```reshape``` but it is a bit clumsy if the size of the datasets is **not** a multiple of the batch size\n",
    "- For CIFAR10 there are 50000 training samples. \n",
    "- That's 781 batches of size 64 and the last has size 16: ```50000=781*64+16```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    imgs,labels=batch\n",
    "    \n",
    "print(imgs.shape,labels.shape)\n",
    "len(train_loader)*batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that we get batches of the same size we use ```drop_last``` in the data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(cifar10_train,shuffle=True,batch_size=batch_size,num_workers=2,drop_last=True)\n",
    "test_loader=DataLoader(cifar10_test,batch_size=batch_size,num_workers=2,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use of ```flatten```\n",
    "\n",
    "- It is more convenient to use ```tensor.flatten(start_dim=d)```\n",
    "- Where ```d``` specifies from which dimension to start \"flattening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(imgs.shape)\n",
    "print(imgs.flatten(start_dim=0).shape,imgs.flatten(start_dim=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-VxiVGnp2LC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize the parameters\n",
    "- The goal is to find the **optimal** values for the parameters, $w$ and $b$. \n",
    "- Intially we give them random values (for weights) and 0 for the bias as shown below. \n",
    "- Note that\n",
    "    - The `reguires_grad` declares a tensor to be a variable\n",
    "    - In previous versions of Pytorch one needed to declare variables explicitly but this is deprecated now. See [here](https://pytorch.org/docs/stable/autograd.html#variable-deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koYSysX4gKjr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "weights=torch.randn(3*32*32,requires_grad=True,dtype=torch.float32)\n",
    "bias=torch.tensor(0.,requires_grad=True,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary cross-entropy loss\n",
    "- Binary cross-entropy is the loss used for binary classification problems.\n",
    "- Recall that $\\sigma(z)$ is the probability that $z(x)$ corresponds to an inanimate object\n",
    "- The corresponding distribution is Bernoulli\n",
    "$$ B(z)=\\sigma^y(1-\\sigma)^{1-y}$$\n",
    "- the log-likelihood\n",
    "$$\\mathcal{L}=y\\log\\sigma+(1-y)\\log(1-\\sigma)$$\n",
    "- Where $y$ is the label corresponding to $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z9ssRJxX6iw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rate=0.015\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss=0\n",
    "    count=0\n",
    "    for imgs,labels in train_loader:\n",
    "        count+=1\n",
    "        imgs=imgs.flatten(start_dim=1)\n",
    "        #compute z=wx+b\n",
    "        z=torch.matmul(imgs,weights)+bias\n",
    "        y_hat=torch.sigmoid(z)\n",
    "        loss=loss_fn(y_hat,labels.float())\n",
    "        # compute the gradients\n",
    "        dw,db=torch.autograd.grad(loss,[weights,bias])\n",
    "        #update the weights and bias\n",
    "        # Note the in-place operation\n",
    "        weights.data-=rate*dw\n",
    "        bias.data-=rate*db\n",
    "        epoch_loss+=loss.item()\n",
    "  \n",
    "    print(\"loss {:.4f}\".format(epoch_loss/count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGEPlrz5l0U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction on the test data\n",
    "\n",
    "- An important measure of any ML method is how well it \"generalizes\". \n",
    "- This is done by using the trained model on **test** data, i.e. data that it **was not** trained on \n",
    "- But the output of our model is the probability that the input is a \"machine\", which could be any value between 0 and 1. \n",
    "- The test labels are discrete values of 0 and 1 so how do we compare them? \n",
    "- We regard a probability $\\ge 0.5$ to be 1 and $< 0.5$ to be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XttSuF7xuVom",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    total=0.\n",
    "    for imgs,labels in loader:\n",
    "        imgs=imgs.flatten(start_dim=1)\n",
    "        z=torch.matmul(imgs,weights)+bias\n",
    "        y_hat=torch.sigmoid(z)\n",
    "        ones=y_hat>0.5\n",
    "        ## count how many outputs are equal to the \"true\" labels\n",
    "        r=ones==labels\n",
    "        ## add them to the total\n",
    "        total+=r.sum()\n",
    "    # len(loader) is the number of batches\n",
    "    return total/(len(loader)*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdCBzLnqc6tO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Abstracting the model and training pipeline using Pytorch\n",
    "\n",
    "- The model we have used  is simple enough to code directly. \n",
    "- We only needed Pytorch to compute the loss and gradients. \n",
    "- For more complicated models this process becomes unwieldy. \n",
    "- We can use Pytorch to abstract away the details.  \n",
    "- The abstractions offered by Pytorch are illustrated below to solve the same problem that we just did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using comet to log results\n",
    "\n",
    "Comet is a cloud platform that integrates with many ML frameworks, including PyTorch, and can be used to log and visualise ML experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = comet_ml.Experiment(workspace=\"COMP6252\",project_name=\"DL intro\",auto_metric_logging=False,auto_param_logging=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1baF5ll16Q3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The model\n",
    "\n",
    "- The model we plan to use is encapsulated in a class that **inherits** from ```torch.nn.Module```\n",
    "\n",
    "- All we need to do is **override** two methods:\n",
    "1. ```__init__```. As you would have guessed this is called when the object is constructed to initialize our model\n",
    "1. ``` forward```. This is called to perform a forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LlED-xrgbiJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,in_features,out_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size=in_features\n",
    "    self.output_size=out_features\n",
    "    # declaring weights and bias as parameters so that they are included\n",
    "    # in the return value of .parameters()\n",
    "    self.weights=nn.Parameter(torch.randn(in_features,requires_grad=True,dtype=torch.float32))\n",
    "    self.bias=nn.Parameter(torch.tensor(0.,requires_grad=True,dtype=torch.float32))\n",
    "    \n",
    "  def forward(self,input):  \n",
    "    y_hat=input.flatten(start_dim=1)\n",
    "    y_hat=torch.matmul(y_hat,self.weights)+self.bias\n",
    "    y_hat=torch.sigmoid(y_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tm160c2I23J3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Note that in the initialization, the weights and bias are constructed as ```Parameter```. \n",
    "- This is so that we can use the ```.parameters()``` call and pass it to the optimizer.\n",
    "- Next we create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9_n6Y2N00Io",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model=Net(3*32*32,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkSOrAn35u5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall that each learning iteration performs a number of steps. \n",
    "1. Compute the forward pass over the input to get the output. This is now done using ```model.forward()``` indirectly by calling ```model(input)```\n",
    "1. Compute the loss using an appropriate loss function. Same as before\n",
    "1. Compute the gradients using ```loss.backward()```.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- ```backward()``` computes the gradient with respect to the parameters AND saves them in the ```.grad``` attributes\n",
    "- For example, if ```p``` is a parameters then ```loss.backward()``` computes the gradient of ```loss``` wrt ```p``` AND saves the result in ```p.grad```\n",
    "- Once the gradients are computed\n",
    "1. The optimizer updates the parameters. \n",
    "    - This is done by the optimizer using ```optimizer.step()```. \n",
    "1. This is important since later on we will use optimizers that use a different strategy to update the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8L9FtlGbz1S3",
    "outputId": "a8377b80-f564-4d1b-dfef-eeabdfdeeaeb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rate=0.015\n",
    "experiment.log_parameters({\"batch_size\":batch_size,\"learning rate\":rate})\n",
    "import torch.optim as optim\n",
    "optimizer=optim.SGD(model.parameters(),lr=rate)\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "epochs=20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  epoch_loss=0\n",
    "  count=0\n",
    "  \n",
    "  for imgs,labels in train_loader:\n",
    "    count+=1\n",
    "  # uses the .forward() method to get y_hat\n",
    "    y_hat=model(imgs)\n",
    "  # as before\n",
    "    loss=loss_fn(y_hat,labels.float())\n",
    "  # Computes the gradients and saves them in the appropriate .grad\n",
    "    loss.backward()\n",
    "  # updates the parameters using the computed .grad\n",
    "    optimizer.step()\n",
    "  # zero the .grad values so that they don't accumulate\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss+=loss.item()\n",
    "  experiment.log_metric(\"loss\",epoch_loss/count,epoch=epoch)\n",
    "  print(\"loss {:.4f}\".format(epoch_loss/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    total=0.\n",
    "    for imgs,labels in loader:\n",
    "        outputs=model(imgs)\n",
    "        ones=outputs>0.5\n",
    "        r=ones==labels\n",
    "        total+=r.sum()\n",
    "    # Compute vector \"y_hat\" predicting\n",
    "    # the probabilities of a machine being present in the picture\n",
    "    \n",
    "    return total/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=predict(test_loader)\n",
    "experiment.log_metric(\"accuracy\",accuracy)\n",
    "### display the experiment inline\n",
    "### a bit clumsy, better to use the link shown when the experiment is created\n",
    "##to see the results\n",
    "#experiment.display()\n",
    "experiment.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyNuNqO6ce7qryqS+HxdL/2J",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10a2f8fa1176415eb1427954d02ac81e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fe3e0a792204b568fdeada38bff559a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "716eed7ac5b242b1a43d095c0376fdfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff7dac6203a4409bd25e5a0fafbfe5f",
      "placeholder": "​",
      "style": "IPY_MODEL_ffe956b562a148a9abb63f496ce91030",
      "value": " 170498071/170498071 [00:02&lt;00:00, 73485295.02it/s]"
     }
    },
    "9daf573e127d45b0a13d392d625f6dd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df2a9b2f02d2434682d4ca213568fbc9",
       "IPY_MODEL_ffce6ae3a0f14491a4690ddec0df4674",
       "IPY_MODEL_716eed7ac5b242b1a43d095c0376fdfd"
      ],
      "layout": "IPY_MODEL_10a2f8fa1176415eb1427954d02ac81e"
     }
    },
    "c25206d0d8be44e3b18028c61228dbd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c49c0f939d094f8bb00e028bcae134cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df2a9b2f02d2434682d4ca213568fbc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc2f840078b44934a9a0a972b2d1a6aa",
      "placeholder": "​",
      "style": "IPY_MODEL_c49c0f939d094f8bb00e028bcae134cb",
      "value": "100%"
     }
    },
    "eff7dac6203a4409bd25e5a0fafbfe5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2f840078b44934a9a0a972b2d1a6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffce6ae3a0f14491a4690ddec0df4674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c25206d0d8be44e3b18028c61228dbd4",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fe3e0a792204b568fdeada38bff559a",
      "value": 170498071
     }
    },
    "ffe956b562a148a9abb63f496ce91030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
