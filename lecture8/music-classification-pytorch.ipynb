{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/UOS-COMP6252/public/blob/main/lecture8/music-classification-pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"text-align: center;\">COMP6252 Deep Learning Technologies</h1>\n","<h2 style=\"text-align: center;\"> Transfer learning- music genre classification</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:18:25.127259Z","iopub.status.busy":"2023-07-18T10:18:25.126827Z","iopub.status.idle":"2023-07-18T10:19:02.251240Z","shell.execute_reply":"2023-07-18T10:19:02.250066Z","shell.execute_reply.started":"2023-07-18T10:18:25.127204Z"},"trusted":true},"outputs":[],"source":["import sys,os\n","from pathlib import Path\n","IN_COLAB = 'google.colab' in sys.modules\n","if IN_COLAB:\n","  from google.colab import files\n","  if not Path('/content/gtzan-dataset-music-genre-classification.zip').is_file(): \n","    file=files.upload() # upload the saved kaggle.json\n","    #### the token can be obtained from your kaggle account by going to settings\n","    #### in the middle of the page under API there is a create new token\n","    #### there is also explanation on how to do it\n","    %mkdir /root/.kaggle\n","    %mv kaggle.json  /root/.kaggle\n","    %kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n","    %unzip -q /content/gtzan-dataset-music-genre-classification.zip\n","    %pip install timm==0.4.12\n","    # get_ipython().system('mkdir /root/.kaggle # on colab you are use root')\n","    # get_ipython().system('mv kaggle.json  /root/.kaggle')\n","    # get_ipython().system('kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification')\n","    # get_ipython().system('unzip -q /content/gtzan-dataset-music-genre-classification.zip')\n","    ####### for some reason the new timm versions are not working\n","    # get_ipython().system('pip install timm==0.4.12')\n","  data_path=\"./Data/images_original\"\n","elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None:\n","  %pip install timm==0.4.12 >/dev/null 2>&1\n","  %pip install comet-ml >/dev/null 2>&1\n","  # get_ipython().system('pip install comet-ml >/dev/null 2>&1')\n","  # get_ipython().system('pip install timm==0.4.12')\n","  ##### make sure that you have added the dataset\n","  data_path=\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original\"\n","else:\n","  #data_path=os.path.join(os.path.expanduser(\"~\"),\"Data/images_original\")\n","  data_path=\"Data/images_original\"\n","  if not os.path.isdir(data_path):\n","    !kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n","    !unzip -q gtzan-dataset-music-genre-classification.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:02.254386Z","iopub.status.busy":"2023-07-18T10:19:02.253958Z","iopub.status.idle":"2023-07-18T10:19:02.262175Z","shell.execute_reply":"2023-07-18T10:19:02.261130Z","shell.execute_reply.started":"2023-07-18T10:19:02.254345Z"},"trusted":true},"outputs":[],"source":["import comet_ml\n","from comet_ml import Experiment\n","import lightning as L\n","from lightning.pytorch import seed_everything\n","from lightning.pytorch.loggers import CSVLogger,CometLogger\n","from lightning.pytorch.callbacks import ModelCheckpoint,Callback\n","\n","# %% In [3]:\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset,DataLoader,random_split\n","import matplotlib.pyplot as plt\n","import copy\n","import torchmetrics\n","from tqdm import tqdm\n","import timm\n","from transformers import AutoModelForImageClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:02.264157Z","iopub.status.busy":"2023-07-18T10:19:02.263712Z","iopub.status.idle":"2023-07-18T10:19:07.157246Z","shell.execute_reply":"2023-07-18T10:19:07.156289Z","shell.execute_reply.started":"2023-07-18T10:19:02.264130Z"},"trusted":true},"outputs":[],"source":["comet_ml.init(project_name=\"music-classification\")\n","experiment=Experiment()\n","hub='timm' # option 'timm','torch','hface'\n","hub='torch'\n","hub='hface'\n","#generic_name='vit'\n","generic_name='resnet18'\n","model_name={'resnet18':'resnet18','resnet50':'resnet50','vit':'vit_base_patch32_224' if hub=='timm' else 'vit_b_32'}\n","\n","hyper_params = {'hub':hub,\"batch_size\": 64, \"num_epochs\": 50, \"learning_rate\": 0.001,\"momentum\":0.9,\"num_workers\":2,\n","                \"model_name\":model_name[generic_name],'pretrained':True,'use_aug':True}\n","experiment.log_parameters(hyper_params)\n","\n","experiment.set_name(hub+'-'+model_name[generic_name])\n","seed_everything(123, workers=True)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dataset=torchvision.datasets.ImageFolder(data_path)\n","num_classes=len(dataset.classes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.165154Z","iopub.status.busy":"2023-07-18T10:19:07.162697Z","iopub.status.idle":"2023-07-18T10:19:07.173876Z","shell.execute_reply":"2023-07-18T10:19:07.172913Z","shell.execute_reply.started":"2023-07-18T10:19:07.165119Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.179911Z","iopub.status.busy":"2023-07-18T10:19:07.178866Z","iopub.status.idle":"2023-07-18T10:19:07.758699Z","shell.execute_reply":"2023-07-18T10:19:07.757562Z","shell.execute_reply.started":"2023-07-18T10:19:07.179875Z"},"trusted":true},"outputs":[],"source":["model=Model(generic_name,num_classes=num_classes)\n","model=model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if hub=='timm':\n","    mean=list(model.cfg()['mean'])\n","    std=list(model.cfg()['std'])\n","else:\n","    mean= [0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.766239Z","iopub.status.busy":"2023-07-18T10:19:07.763775Z","iopub.status.idle":"2023-07-18T10:19:07.785477Z","shell.execute_reply":"2023-07-18T10:19:07.784250Z","shell.execute_reply.started":"2023-07-18T10:19:07.766188Z"},"trusted":true},"outputs":[],"source":["\n","class CustomDataset(Dataset):\n","    def __init__(self,subset,transform=None):\n","        self.subset=subset\n","        self.transform=transform\n","    def __getitem__(self,idx):\n","        x,y=self.subset[idx]\n","        if self.transform:\n","            x=self.transform(x)\n","        return x,y\n","    def __len__(self):\n","        return len(self.subset)\n","\n","data_transforms = {\n","     'train':  transforms.Compose([ transforms.TrivialAugmentWide(),\n","                                   transforms.CenterCrop(224),transforms.ToTensor(),\n","                                   transforms.Normalize(mean, std)]) if hyper_params['use_aug'] else\n","    transforms.Compose([\n","                                   transforms.CenterCrop(224),transforms.ToTensor(),\n","                                   transforms.Normalize(mean, std)])\n","    ,\n","  \n","    'val': transforms.Compose([transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","    \n","    'test': transforms.Compose([transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","}\n","\n","datasets={}\n","datasets['train'],datasets['val'],datasets['test']=random_split(dataset,lengths=[0.7,0.2,0.1])\n","image_datasets = {x: CustomDataset(datasets[x],data_transforms[x])\n","                  for x in ['train', 'val','test']}\n","dataset_sizes={x:len(image_datasets[x]) for x in ['train','val','test']}\n","dataloaders={x:DataLoader(image_datasets[x], batch_size=hyper_params['batch_size'],\n","                                             shuffle=True if x=='train' else False, num_workers=hyper_params[\"num_workers\"])\n","                                             for x in ['train','val','test']}\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timm_model=timm.create_model('resnet18',pretrained=True,num_classes=num_classes)  \n","weights_enum=torch.hub.load('pytorch/vision','get_model_weights','resnet18')\n","torch_model=torch.hub.load('pytorch/vision','resnet18',weights=weights_enum)\n","hface_model=AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n","timm_modules=[m for m in timm_model.named_modules()]\n","torch_modules=[m for m in torch_model.named_modules()]\n","hface_modules=[m for m in hface_model.named_modules()]\n","print(timm_modules[-1])\n","print(torch_modules[-1])\n","print(hface_modules[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class Model(nn.Module):\n","    def __init__(self,generic_name,num_classes):\n","        super().__init__()\n","        # self.model=timm.create_model(model_name=model_name,pretrained=True)\n","        # for p in self.model.parameters():\n","        #     p.requires_grad=False   \n","        if hub=='timm':\n","            self.model=timm.create_model(model_name=model_name[generic_name],num_classes=num_classes,pretrained=hyper_params['pretrained'])\n","        if hub=='torch':\n","            if hyper_params['pretrained']:\n","                weights_enum=torch.hub.load('pytorch/vision','get_model_weights',model_name[generic_name])\n","                self.model=torch.hub.load('pytorch/vision',model_name[generic_name],weights=weights_enum)\n","            else:\n","                self.model=torch.hub.load('pytorch/vision',model_name[generic_name],weights=None)\n","            if generic_name.startswith('vit'):\n","              self.model.heads=nn.Linear(self.model.heads[0].in_features,num_classes)\n","            else:\n","              self.model.fc=nn.Linear(self.model.fc.in_features,num_classes)\n","        if hub=='hface':\n","            self.model=AutoModelForImageClassification.from_pretrained('microsoft/resnet-18')\n","            self.model.classifier[1]=nn.Linear(in_features=512,out_features=num_classes)\n","    \n","    def forward(self,x):\n","        return self.model(x).logits if hub=='hface' else self.model(x)\n","    def cfg(self):\n","        return self.model.default_cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.793307Z","iopub.status.busy":"2023-07-18T10:19:07.790194Z","iopub.status.idle":"2023-07-18T10:19:07.804295Z","shell.execute_reply":"2023-07-18T10:19:07.803302Z","shell.execute_reply.started":"2023-07-18T10:19:07.793269Z"},"trusted":true},"outputs":[],"source":["def test(model, criterion,loader):\n","    with torch.no_grad():\n","        model.eval()   \n","        running_loss = 0.0        \n","        test_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        confmat=torchmetrics.ConfusionMatrix(task='multiclass',num_classes=num_classes).to(device)\n","        for inputs, labels in loader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                confmat.update(preds,labels)\n","                batch_acc=test_acc(preds,labels.data)\n","            \n","        total_acc=test_acc.compute()\n","       \n","    return total_acc,confmat"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.811610Z","iopub.status.busy":"2023-07-18T10:19:07.808741Z","iopub.status.idle":"2023-07-18T10:19:07.822284Z","shell.execute_reply":"2023-07-18T10:19:07.821323Z","shell.execute_reply.started":"2023-07-18T10:19:07.811574Z"},"trusted":true},"outputs":[],"source":["def validate(model, criterion,loader):\n","    with torch.no_grad():\n","        model.eval()   \n","        running_loss = 0.0        \n","        val_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        for inputs, labels in loader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                running_loss += loss.item() * hyper_params['batch_size']\n","                batch_acc=val_acc(preds,labels.data)\n","            \n","        epoch_loss = running_loss / (len(loader)*hyper_params['batch_size'])\n","        epoch_acc=val_acc.compute()\n","       \n","    return epoch_loss,epoch_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.829914Z","iopub.status.busy":"2023-07-18T10:19:07.826961Z","iopub.status.idle":"2023-07-18T10:19:07.847798Z","shell.execute_reply":"2023-07-18T10:19:07.846669Z","shell.execute_reply.started":"2023-07-18T10:19:07.829873Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer,scheduler=None, num_epochs=100):\n","    for epoch in range(hyper_params['num_epochs']):\n","        \n","        model.train()  \n","        running_loss=0.\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        best_acc = 0.0\n","      \n","        train_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        loop=tqdm(dataloaders['train'])\n","        loop.set_description(f\"Epoch [{epoch+1}/{hyper_params['num_epochs']}]\")\n","\n","        for inputs, labels in loop:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            batch_acc=train_acc(preds,labels.data)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss =0.9*running_loss+0.1*loss.item() \n","            if epoch>0:\n","                 loop.set_postfix(loss=running_loss,t_acc=epoch_acc.item(),val_acc=v_acc.item())\n","            else:\n","                 loop.set_postfix(loss=running_loss)\n","       \n","\n","        epoch_loss = running_loss / dataset_sizes['train']\n","        epoch_acc=train_acc.compute()        \n","        experiment.log_metric(epoch_loss,epoch)\n","        v_loss,v_acc=validate(model,criterion,dataloaders['val'])\n","        experiment.log_metrics({\"train_loss\":epoch_loss,\"train_acc\":epoch_acc},epoch=epoch)\n","\n","        experiment.log_metrics({\"val_loss\":v_loss,\"val_acc\":v_acc},epoch=epoch)\n","\n","        if  v_acc > best_acc:\n","                best_acc = v_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        train_acc.reset()\n","    ## training is done. Return the model with the best validation accuracy\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-18T10:19:07.852454Z","iopub.status.busy":"2023-07-18T10:19:07.851658Z","iopub.status.idle":"2023-07-18T10:33:25.729381Z","shell.execute_reply":"2023-07-18T10:33:25.728310Z","shell.execute_reply.started":"2023-07-18T10:19:07.852419Z"},"trusted":true},"outputs":[],"source":["\n","\n","model=model.to(device)\n","optimizer=optim.SGD(model.parameters(),lr=hyper_params['learning_rate'],momentum=hyper_params['momentum'])\n","#optimizer=optim.Adam(model.parameters(),lr=0.0001)\n","criterion=nn.functional.cross_entropy\n","\n","model=train_model(model=model,criterion=criterion,optimizer=optimizer,scheduler=None,num_epochs=hyper_params['num_epochs'])\n","\n","\n","test_acc,confmat=test(model,criterion,dataloaders['test'])\n","print(test_acc.item())\n","experiment.log_metric(\"test_acc\",test_acc.item())\n","\n","print(test_acc.item())\n","\n","mat=confmat.compute().cpu().numpy()\n","experiment.log_confusion_matrix(matrix=mat,labels=dataset.classes)\n","experiment.end()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
