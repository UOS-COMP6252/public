{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/UOS-COMP6252/public/blob/main/lecture8/music-classification-pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"text-align: center;\">COMP6252 Deep Learning Technologies</h1>\n","<h2 style=\"text-align: center;\"> Transfer learning- music genre classification</h2>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:18:25.127259Z","iopub.status.busy":"2023-07-18T10:18:25.126827Z","iopub.status.idle":"2023-07-18T10:19:02.251240Z","shell.execute_reply":"2023-07-18T10:19:02.250066Z","shell.execute_reply.started":"2023-07-18T10:18:25.127204Z"},"trusted":true},"outputs":[],"source":["import sys,os\n","from pathlib import Path\n","IN_COLAB = 'google.colab' in sys.modules\n","if IN_COLAB:\n","  from google.colab import files\n","  if not Path('/content/gtzan-dataset-music-genre-classification.zip').is_file(): \n","    file=files.upload() # upload the saved kaggle.json\n","    #### the token can be obtained from your kaggle account by going to settings\n","    #### in the middle of the page under API there is a create new token\n","    #### there is also explanation on how to do it\n","    %mkdir /root/.kaggle\n","    %mv kaggle.json  /root/.kaggle\n","    !kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n","    !unzip -q /content/gtzan-dataset-music-genre-classification.zip\n","    %pip install timm==0.4.12\n","    # get_ipython().system('mkdir /root/.kaggle # on colab you are use root')\n","    # get_ipython().system('mv kaggle.json  /root/.kaggle')\n","    # get_ipython().system('kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification')\n","    # get_ipython().system('unzip -q /content/gtzan-dataset-music-genre-classification.zip')\n","    ####### for some reason the new timm versions are not working\n","    # get_ipython().system('pip install timm==0.4.12')\n","  data_path=\"./Data/images_original\"\n","elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None:\n","  %pip install timm==0.4.12 >/dev/null 2>&1\n","  %pip install comet-ml >/dev/null 2>&1\n","  # get_ipython().system('pip install comet-ml >/dev/null 2>&1')\n","  # get_ipython().system('pip install timm==0.4.12')\n","  ##### make sure that you have added the dataset\n","  data_path=\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original\"\n","else:\n","  #data_path=os.path.join(os.path.expanduser(\"~\"),\"Data/images_original\")\n","  data_path=\"Data/images_original\"\n","  if not os.path.isdir(data_path):\n","    !kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n","    !unzip -q gtzan-dataset-music-genre-classification.zip\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import getpass\n","import os\n","try:\n","  import comet_ml\n","  from comet_ml import Experiment\n","except ModuleNotFoundError:\n","  %pip install comet_ml\n","  from comet_ml import Experiment\n","  import comet_ml\n","comet_api_key=os.environ.get(\"COMET_API_KEY\")\n","if comet_api_key is None:\n","  comet_api_key=getpass.getpass(\"Enter key\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["try:\n","    from torchmetrics import ConfusionMatrix\n","    from torchmetrics.classification import MulticlassAccuracy\n","except ModuleNotFoundError:\n","    %pip install torchmetrics\n","    from torchmetrics import ConfusionMatrix\n","    from torchmetrics.classification import MulticlassAccuracy"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:02.254386Z","iopub.status.busy":"2023-07-18T10:19:02.253958Z","iopub.status.idle":"2023-07-18T10:19:02.262175Z","shell.execute_reply":"2023-07-18T10:19:02.261130Z","shell.execute_reply.started":"2023-07-18T10:19:02.254345Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset,DataLoader,random_split\n","import matplotlib.pyplot as plt\n","import copy\n","import torchmetrics\n","from tqdm import tqdm\n","import timm\n","from transformers import AutoModelForImageClassification"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["seed=9 \n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic=True"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:02.264157Z","iopub.status.busy":"2023-07-18T10:19:02.263712Z","iopub.status.idle":"2023-07-18T10:19:07.157246Z","shell.execute_reply":"2023-07-18T10:19:07.156289Z","shell.execute_reply.started":"2023-07-18T10:19:02.264130Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/hikmat-farhat-gmail-com/music-classification/17b3e7f6b07242daa91f2ffa4675f28b\n","\n"]}],"source":["comet_ml.init(api_key=comet_api_key,project_name=\"music-classification\")\n","experiment=Experiment()\n","hub='timm' # option 'timm','torch','hface'\n","hub='torch'\n","hub='hface'\n","#generic_name='vit'\n","generic_name='resnet18'\n","model_name={'resnet18':'resnet18','resnet50':'resnet50','vit':'vit_base_patch32_224' if hub=='timm' else 'vit_b_32'}\n","\n","hyper_params = {'hub':hub,\"batch_size\": 64, \"num_epochs\": 50, \"learning_rate\": 0.001,\"momentum\":0.9,\"num_workers\":2,\n","                \"model_name\":model_name[generic_name],'pretrained':True,'use_aug':True}\n","experiment.log_parameters(hyper_params)\n","\n","experiment.set_name(hub+'-'+model_name[generic_name])\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dataset=torchvision.datasets.ImageFolder(data_path)\n","num_classes=len(dataset.classes)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["mean= [0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.766239Z","iopub.status.busy":"2023-07-18T10:19:07.763775Z","iopub.status.idle":"2023-07-18T10:19:07.785477Z","shell.execute_reply":"2023-07-18T10:19:07.784250Z","shell.execute_reply.started":"2023-07-18T10:19:07.766188Z"},"trusted":true},"outputs":[],"source":["\n","class CustomDataset(Dataset):\n","    def __init__(self,subset,transform=None):\n","        self.subset=subset\n","        self.transform=transform\n","    def __getitem__(self,idx):\n","        x,y=self.subset[idx]\n","        if self.transform:\n","            x=self.transform(x)\n","        return x,y\n","    def __len__(self):\n","        return len(self.subset)\n","\n","data_transforms = {\n","     'train':  transforms.Compose([ transforms.TrivialAugmentWide(),\n","                                   transforms.CenterCrop(224),transforms.ToTensor(),\n","                                   transforms.Normalize(mean, std)]) if hyper_params['use_aug'] else\n","    transforms.Compose([\n","                                   transforms.CenterCrop(224),transforms.ToTensor(),\n","                                   transforms.Normalize(mean, std)])\n","    ,\n","  \n","    'val': transforms.Compose([transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","    \n","    'test': transforms.Compose([transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","}\n","\n","datasets={}\n","datasets['train'],datasets['val'],datasets['test']=random_split(dataset,lengths=[0.7,0.2,0.1])\n","image_datasets = {x: CustomDataset(datasets[x],data_transforms[x])\n","                  for x in ['train', 'val','test']}\n","dataset_sizes={x:len(image_datasets[x]) for x in ['train','val','test']}\n","dataloaders={x:DataLoader(image_datasets[x], batch_size=hyper_params['batch_size'],\n","                                             shuffle=True if x=='train' else False, num_workers=hyper_params[\"num_workers\"])\n","                                             for x in ['train','val','test']}\n","\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /home/user/.cache/torch/hub/pytorch_vision_main\n","Using cache found in /home/user/.cache/torch/hub/pytorch_vision_main\n","/home/user/anaconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["('fc', Linear(in_features=512, out_features=10, bias=True))\n","('fc', Linear(in_features=512, out_features=1000, bias=True))\n","('classifier.1', Linear(in_features=512, out_features=1000, bias=True))\n"]}],"source":["timm_model=timm.create_model('resnet18',pretrained=True,num_classes=num_classes)  \n","weights_enum=torch.hub.load('pytorch/vision','get_model_weights','resnet18')\n","torch_model=torch.hub.load('pytorch/vision','resnet18',weights=weights_enum)\n","hface_model=AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n","timm_modules=[m for m in timm_model.named_modules()]\n","torch_modules=[m for m in torch_model.named_modules()]\n","hface_modules=[m for m in hface_model.named_modules()]\n","print(timm_modules[-1])\n","print(torch_modules[-1])\n","print(hface_modules[-1])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\n","class Model(nn.Module):\n","    def __init__(self,generic_name,num_classes):\n","        super().__init__()\n","        # self.model=timm.create_model(model_name=model_name,pretrained=True)\n","        # for p in self.model.parameters():\n","        #     p.requires_grad=False   \n","        if hub=='timm':\n","            self.model=timm.create_model(model_name=model_name[generic_name],num_classes=num_classes,pretrained=hyper_params['pretrained'])\n","        if hub=='torch':\n","            if hyper_params['pretrained']:\n","                weights_enum=torch.hub.load('pytorch/vision','get_model_weights',model_name[generic_name])\n","                self.model=torch.hub.load('pytorch/vision',model_name[generic_name],weights=weights_enum)\n","            else:\n","                self.model=torch.hub.load('pytorch/vision',model_name[generic_name],weights=None)\n","            if generic_name.startswith('vit'):\n","              self.model.heads=nn.Linear(self.model.heads[0].in_features,num_classes)\n","            else:\n","              self.model.fc=nn.Linear(self.model.fc.in_features,num_classes)\n","        if hub=='hface':\n","            self.model=AutoModelForImageClassification.from_pretrained('microsoft/resnet-18')\n","            self.model.classifier[1]=nn.Linear(in_features=512,out_features=num_classes)\n","    \n","    def forward(self,x):\n","        return self.model(x).logits if hub=='hface' else self.model(x)\n","    def cfg(self):\n","        return self.model.default_cfg"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.793307Z","iopub.status.busy":"2023-07-18T10:19:07.790194Z","iopub.status.idle":"2023-07-18T10:19:07.804295Z","shell.execute_reply":"2023-07-18T10:19:07.803302Z","shell.execute_reply.started":"2023-07-18T10:19:07.793269Z"},"trusted":true},"outputs":[],"source":["def test(model, criterion,loader):\n","    with torch.no_grad():\n","        model.eval()   \n","        running_loss = 0.0        \n","        test_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        confmat=torchmetrics.ConfusionMatrix(task='multiclass',num_classes=num_classes).to(device)\n","        for inputs, labels in loader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                confmat.update(preds,labels)\n","                batch_acc=test_acc(preds,labels.data)\n","            \n","        total_acc=test_acc.compute()\n","       \n","    return total_acc,confmat"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.811610Z","iopub.status.busy":"2023-07-18T10:19:07.808741Z","iopub.status.idle":"2023-07-18T10:19:07.822284Z","shell.execute_reply":"2023-07-18T10:19:07.821323Z","shell.execute_reply.started":"2023-07-18T10:19:07.811574Z"},"trusted":true},"outputs":[],"source":["def validate(model, criterion,loader):\n","    with torch.no_grad():\n","        model.eval()   \n","        running_loss = 0.0        \n","        val_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        for inputs, labels in loader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                running_loss += loss.item() * hyper_params['batch_size']\n","                batch_acc=val_acc(preds,labels.data)\n","            \n","        epoch_loss = running_loss / (len(loader)*hyper_params['batch_size'])\n","        epoch_acc=val_acc.compute()\n","       \n","    return epoch_loss,epoch_acc"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T10:19:07.829914Z","iopub.status.busy":"2023-07-18T10:19:07.826961Z","iopub.status.idle":"2023-07-18T10:19:07.847798Z","shell.execute_reply":"2023-07-18T10:19:07.846669Z","shell.execute_reply.started":"2023-07-18T10:19:07.829873Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer,scheduler=None, num_epochs=100):\n","    for epoch in range(hyper_params['num_epochs']):\n","        \n","        model.train()  \n","        running_loss=0.\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        best_acc = 0.0\n","      \n","        train_acc=torchmetrics.Accuracy('multiclass',num_classes=num_classes).to(device)\n","        loop=tqdm(dataloaders['train'])\n","        loop.set_description(f\"Epoch [{epoch+1}/{hyper_params['num_epochs']}]\")\n","\n","        for inputs, labels in loop:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            batch_acc=train_acc(preds,labels.data)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss =0.9*running_loss+0.1*loss.item() \n","            if epoch>0:\n","                 loop.set_postfix(loss=running_loss,t_acc=epoch_acc.item(),val_acc=v_acc.item())\n","            else:\n","                 loop.set_postfix(loss=running_loss)\n","       \n","\n","        epoch_loss = running_loss / dataset_sizes['train']\n","        epoch_acc=train_acc.compute()        \n","        experiment.log_metric(epoch_loss,epoch)\n","        v_loss,v_acc=validate(model,criterion,dataloaders['val'])\n","        experiment.log_metrics({\"train_loss\":epoch_loss,\"train_acc\":epoch_acc},epoch=epoch)\n","\n","        experiment.log_metrics({\"val_loss\":v_loss,\"val_acc\":v_acc},epoch=epoch)\n","\n","        if  v_acc > best_acc:\n","                best_acc = v_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        train_acc.reset()\n","    ## training is done. Return the model with the best validation accuracy\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-18T10:19:07.852454Z","iopub.status.busy":"2023-07-18T10:19:07.851658Z","iopub.status.idle":"2023-07-18T10:33:25.729381Z","shell.execute_reply":"2023-07-18T10:33:25.728310Z","shell.execute_reply.started":"2023-07-18T10:19:07.852419Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch [1/50]: 100%|██████████| 11/11 [00:01<00:00,  6.28it/s, loss=1.6] \n","Epoch [2/50]: 100%|██████████| 11/11 [00:01<00:00,  7.78it/s, loss=1.42, t_acc=0.117, val_acc=0.18]\n","Epoch [3/50]: 100%|██████████| 11/11 [00:01<00:00,  7.60it/s, loss=1.26, t_acc=0.296, val_acc=0.385]\n","Epoch [4/50]: 100%|██████████| 11/11 [00:01<00:00,  7.88it/s, loss=1.12, t_acc=0.419, val_acc=0.445]\n","Epoch [5/50]: 100%|██████████| 11/11 [00:01<00:00,  7.96it/s, loss=1.01, t_acc=0.464, val_acc=0.515] \n","Epoch [6/50]: 100%|██████████| 11/11 [00:01<00:00,  7.34it/s, loss=0.944, t_acc=0.527, val_acc=0.535]\n","Epoch [7/50]: 100%|██████████| 11/11 [00:01<00:00,  7.90it/s, loss=0.887, t_acc=0.581, val_acc=0.56]\n","Epoch [8/50]: 100%|██████████| 11/11 [00:01<00:00,  7.96it/s, loss=0.827, t_acc=0.59, val_acc=0.625]\n","Epoch [9/50]: 100%|██████████| 11/11 [00:01<00:00,  7.89it/s, loss=0.745, t_acc=0.64, val_acc=0.63]\n","Epoch [10/50]: 100%|██████████| 11/11 [00:01<00:00,  7.89it/s, loss=0.675, t_acc=0.671, val_acc=0.625]\n","Epoch [11/50]: 100%|██████████| 11/11 [00:01<00:00,  7.95it/s, loss=0.652, t_acc=0.701, val_acc=0.625]\n","Epoch [12/50]: 100%|██████████| 11/11 [00:01<00:00,  7.97it/s, loss=0.64, t_acc=0.704, val_acc=0.63] \n","Epoch [13/50]: 100%|██████████| 11/11 [00:01<00:00,  7.71it/s, loss=0.636, t_acc=0.706, val_acc=0.665]\n","Epoch [14/50]: 100%|██████████| 11/11 [00:01<00:00,  7.91it/s, loss=0.547, t_acc=0.716, val_acc=0.645]\n","Epoch [15/50]: 100%|██████████| 11/11 [00:01<00:00,  7.79it/s, loss=0.539, t_acc=0.764, val_acc=0.65]\n","Epoch [16/50]: 100%|██████████| 11/11 [00:01<00:00,  7.92it/s, loss=0.493, t_acc=0.76, val_acc=0.675]\n","Epoch [17/50]: 100%|██████████| 11/11 [00:01<00:00,  7.93it/s, loss=0.492, t_acc=0.793, val_acc=0.68]\n","Epoch [18/50]: 100%|██████████| 11/11 [00:01<00:00,  7.62it/s, loss=0.441, t_acc=0.783, val_acc=0.67]\n","Epoch [19/50]: 100%|██████████| 11/11 [00:01<00:00,  7.99it/s, loss=0.418, t_acc=0.804, val_acc=0.69]\n","Epoch [20/50]: 100%|██████████| 11/11 [00:01<00:00,  7.73it/s, loss=0.396, t_acc=0.836, val_acc=0.685]\n","Epoch [21/50]: 100%|██████████| 11/11 [00:01<00:00,  7.84it/s, loss=0.396, t_acc=0.856, val_acc=0.7]\n","Epoch [22/50]: 100%|██████████| 11/11 [00:01<00:00,  7.89it/s, loss=0.384, t_acc=0.853, val_acc=0.71]\n","Epoch [23/50]: 100%|██████████| 11/11 [00:01<00:00,  7.88it/s, loss=0.36, t_acc=0.827, val_acc=0.695] \n","Epoch [24/50]: 100%|██████████| 11/11 [00:01<00:00,  7.90it/s, loss=0.331, t_acc=0.849, val_acc=0.715]\n","Epoch [25/50]: 100%|██████████| 11/11 [00:01<00:00,  7.93it/s, loss=0.342, t_acc=0.859, val_acc=0.685]\n","Epoch [26/50]: 100%|██████████| 11/11 [00:01<00:00,  7.98it/s, loss=0.309, t_acc=0.854, val_acc=0.705]\n","Epoch [27/50]: 100%|██████████| 11/11 [00:01<00:00,  7.75it/s, loss=0.343, t_acc=0.869, val_acc=0.73]\n","Epoch [28/50]: 100%|██████████| 11/11 [00:01<00:00,  7.88it/s, loss=0.297, t_acc=0.851, val_acc=0.73]\n","Epoch [29/50]: 100%|██████████| 11/11 [00:01<00:00,  7.78it/s, loss=0.278, t_acc=0.881, val_acc=0.735]\n","Epoch [30/50]: 100%|██████████| 11/11 [00:01<00:00,  7.87it/s, loss=0.29, t_acc=0.876, val_acc=0.69] \n","Epoch [31/50]: 100%|██████████| 11/11 [00:01<00:00,  7.86it/s, loss=0.259, t_acc=0.883, val_acc=0.71]\n","Epoch [32/50]: 100%|██████████| 11/11 [00:01<00:00,  7.99it/s, loss=0.276, t_acc=0.89, val_acc=0.745]\n","Epoch [33/50]: 100%|██████████| 11/11 [00:01<00:00,  7.88it/s, loss=0.255, t_acc=0.876, val_acc=0.74]\n","Epoch [34/50]: 100%|██████████| 11/11 [00:01<00:00,  7.91it/s, loss=0.218, t_acc=0.896, val_acc=0.705]\n","Epoch [35/50]: 100%|██████████| 11/11 [00:01<00:00,  8.06it/s, loss=0.263, t_acc=0.903, val_acc=0.685]\n","Epoch [36/50]: 100%|██████████| 11/11 [00:01<00:00,  7.74it/s, loss=0.234, t_acc=0.89, val_acc=0.735]\n","Epoch [37/50]: 100%|██████████| 11/11 [00:01<00:00,  8.00it/s, loss=0.237, t_acc=0.897, val_acc=0.745]\n","Epoch [38/50]: 100%|██████████| 11/11 [00:01<00:00,  7.93it/s, loss=0.212, t_acc=0.909, val_acc=0.74]\n","Epoch [39/50]: 100%|██████████| 11/11 [00:01<00:00,  7.93it/s, loss=0.212, t_acc=0.91, val_acc=0.715]\n","Epoch [40/50]: 100%|██████████| 11/11 [00:01<00:00,  7.94it/s, loss=0.225, t_acc=0.921, val_acc=0.73]\n","Epoch [41/50]: 100%|██████████| 11/11 [00:01<00:00,  7.95it/s, loss=0.206, t_acc=0.893, val_acc=0.74]\n","Epoch [42/50]: 100%|██████████| 11/11 [00:01<00:00,  7.95it/s, loss=0.208, t_acc=0.914, val_acc=0.725]\n","Epoch [43/50]: 100%|██████████| 11/11 [00:01<00:00,  7.99it/s, loss=0.216, t_acc=0.911, val_acc=0.725]\n","Epoch [44/50]: 100%|██████████| 11/11 [00:01<00:00,  7.96it/s, loss=0.19, t_acc=0.907, val_acc=0.705] \n","Epoch [45/50]: 100%|██████████| 11/11 [00:01<00:00,  7.88it/s, loss=0.224, t_acc=0.917, val_acc=0.705]\n","Epoch [46/50]: 100%|██████████| 11/11 [00:01<00:00,  7.99it/s, loss=0.172, t_acc=0.901, val_acc=0.72]\n","Epoch [47/50]: 100%|██████████| 11/11 [00:01<00:00,  7.89it/s, loss=0.17, t_acc=0.927, val_acc=0.74] \n","Epoch [48/50]: 100%|██████████| 11/11 [00:01<00:00,  8.00it/s, loss=0.223, t_acc=0.924, val_acc=0.725]\n","Epoch [49/50]: 100%|██████████| 11/11 [00:01<00:00,  7.94it/s, loss=0.161, t_acc=0.907, val_acc=0.725]\n","Epoch [50/50]: 100%|██████████| 11/11 [00:01<00:00,  7.99it/s, loss=0.212, t_acc=0.93, val_acc=0.725]\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/hikmat-farhat-gmail-com/music-classification/17b3e7f6b07242daa91f2ffa4675f28b\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.000230171735943512   : 48\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00024243454047999637 : 46\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0002457858083359199  : 45\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00027158037781067283 : 43\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0002947965019613536  : 40\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00029690304647908756 : 41\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003022248074556645  : 49\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003027701548410276  : 38\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00030331675465514424 : 37\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003092578838186135  : 42\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003115906219255661  : 33\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00031888924898543995 : 47\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00031951869261007457 : 44\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003216247211728821  : 39\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003341005691413392  : 35\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00033817710654313976 : 36\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003644295525140557  : 32\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00036999215552859286 : 30\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00037592565783785146 : 34\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003948218505803571  : 31\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0003976779831635774  : 28\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00041372753706003557 : 29\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00042425300663244175 : 27\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0004414220478059106  : 25\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00047260093131802644 : 23\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0004892790832937591  : 24\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0004902364733696536  : 26\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0005140097414001436  : 22\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0005483014613494622  : 21\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0005654815528175806  : 19\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0005656718247177635  : 20\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0005975284271240724  : 18\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0006302909116952779  : 17\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0007029653540205442  : 16\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0007041593642742984  : 15\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0007697397446678662  : 14\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0007815714012846271  : 13\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0009083701853930713  : 12\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.000914289715393307   : 11\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.000931414700684323   : 10\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0009645145927648731  : 9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0010636622266207876  : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0011816722979146317  : 7\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0012667571625985152  : 6\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.00134878729746173    : 5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.001445461562438084   : 4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0016023131959159859  : 3\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0018050813414212713  : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.0020263493403944607  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     0.002289833218447654   : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [55]              : (0.14564886689186096, 2.4689199924468994)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_acc               : 0.7373737096786499\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_acc [50]         : (0.11714285612106323, 0.9300000071525574)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [50]        : (0.000230171735943512, 0.002289833218447654)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_acc [50]           : (0.18000000715255737, 0.7450000047683716)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [50]          : (0.7101612538099289, 2.2545343041419983)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : hface-resnet18\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hub           : hface\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate : 0.001\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_name    : resnet18\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum      : 0.9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_epochs    : 50\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_workers   : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained    : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_aug       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix             : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (35.02 KB)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"]},{"name":"stdout","output_type":"stream","text":["0.7373737096786499\n","0.7373737096786499\n"]}],"source":["model=Model(generic_name,num_classes=num_classes)\n","\n","model=model.to(device)\n","optimizer=optim.SGD(model.parameters(),lr=hyper_params['learning_rate'],momentum=hyper_params['momentum'])\n","#optimizer=optim.Adam(model.parameters(),lr=0.0001)\n","criterion=nn.functional.cross_entropy\n","\n","model=train_model(model=model,criterion=criterion,optimizer=optimizer,scheduler=None,num_epochs=hyper_params['num_epochs'])\n","\n","\n","test_acc,confmat=test(model,criterion,dataloaders['test'])\n","print(test_acc.item())\n","experiment.log_metric(\"test_acc\",test_acc.item())\n","\n","print(test_acc.item())\n","\n","mat=confmat.compute().cpu().numpy()\n","experiment.log_confusion_matrix(matrix=mat,labels=dataset.classes)\n","experiment.end()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
