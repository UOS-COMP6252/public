{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/UOS-COMP6252/public/blob/main/lecture3/backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backpropagation practical exercise\n",
    "Learning outcomes: you will be able to\n",
    "1. Describe how the backward graph is implemented in PyTorch using the ```grad_fn.next_functions```\n",
    "1. Explain how PyTorch uses computational graphs to implement backpropagation   \n",
    "1. Apply PyTorch ```grad_fn``` to compute the gradient of any expression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backpropagation\n",
    " - We saw that PyTorch can compute the gradient to any function. \n",
    " - To accomplish this, PyTorch uses three concepts:\n",
    " \n",
    " 1. Computational graph\n",
    " 1. \"Database\" of derivatives to **primitive** functions\n",
    " 1. Chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Consider the following computations:\n",
    "$$\n",
    "\\begin{align*}\n",
    "a&=2\\\\\n",
    "b&=4\\\\\n",
    "c&=a+b\\\\\n",
    "d&=\\log(a)*\\log(b)\\\\\n",
    "e&=c*d\n",
    "\\end{align*}\n",
    "$$\n",
    " \n",
    "\n",
    " Where $\\log(x)$ is the log base two. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For every **primitive** operation, PyTorch \"knows\" its derivative. \n",
    "- For example, PyTorch has the following rules stored and can look them up when needed.\n",
    "\n",
    "1. $\\frac{\\partial\\log(x)}{\\partial x}=\\frac{1}{x*\\ln(2)}$\n",
    "1. $\\frac{\\partial (x*y)}{\\partial x}=y$\n",
    "1. $\\frac{\\partial (x*y)}{\\partial y}=x$\n",
    "1. $\\frac{\\partial (x+y)}{\\partial x}=1$\n",
    "1. $\\frac{\\partial (x+y)}{\\partial y}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The PyTorch code corresponding to the example is shown below. Note:\n",
    "1. For each **leaf** tensor ```X```, the gradient is stored in ```X.grad```\n",
    "1. The values for **non-leaf** node ```Y``` is **not** saved, unless ```Y.retain_grad()``` is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6562) tensor(4.1640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(4.,requires_grad=True)\n",
    "c=a+b # c=6\n",
    "d=torch.log2(a)*torch.log2(b)# d=2\n",
    "#d.retain_grad()\n",
    "e=c*d\n",
    "e.backward(retain_graph=True)\n",
    "#e.backward()\n",
    "print(a.grad,b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We will be going through the computation step by step to obtain the same result\n",
    "- How does ```backward``` work? \n",
    "- Recursively calls the ```.grad_fn``` of each node in the graph\n",
    "- We use ```.no_grad()``` so that PyTorch does not build a CG  for the computations below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Note that the code below will give an **error** if we use ```e.backward()``` instead of  ```e.backward(retain_graph=True)```because the graph is **destroyed** after the call to ```.backward()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient of e wrt to c=2.0, wrt to d=6.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dedc,dedd=e.grad_fn(torch.tensor(1.))\n",
    "    print(\"gradient of e wrt to c={}, wrt to d={}\".format(dedc,dedd))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c's contribution to grad of e wrt to a and b: (tensor(2.), tensor(2.))\n",
      "What does this output (tensor(12.), tensor(6.)) correspond to?\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"c\\'s contribution to grad of e wrt to a and b: {}\".format(c.grad_fn(dedc)))\n",
    "    print(\"What does this output {} correspond to?\".format(d.grad_fn(dedd)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial d}{\\partial \\log a}=\\log b=2$ and $\\frac{\\partial d}{\\partial \\log b}=\\log a=1$\n",
    "Multiply by $\\frac{\\partial e}{\\partial d}=6$ to get 12 and 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that the results for ```c.grad_fn``` are added to ```a``` and ```b```\n",
    "- but the results for ```d.grad_fn``` are fed to **unnamed** intermediate nodes\n",
    "- How does one proceed? How does PyTorch keep track?\n",
    "- Actually PyTorch keeps track of the next ```grad_fn``` to call using ```next_functions``` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<Log2Backward0 object at 0x7fe8a2ddd4b0>, 0), (<Log2Backward0 object at 0x7fe8a2ddd720>, 0))\n"
     ]
    }
   ],
   "source": [
    "print(d.grad_fn.next_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- it is a tuple of pairs of the form (function,index)\n",
    "- We can almost always ignore the index. For the vast majority of operations there is only one value 0\n",
    "- Also, since most operations are binary the tuple is usually a pair\n",
    "- In summary, for most operations that we encounter ```.next_functions``` returns a pair of pairs where the idex in each pair can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient of e wrt to c is=2.0, wrt to d=6.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #the gradients are accumulated, we need to reset\n",
    "    a.grad,b.grad=None,None\n",
    "    # The \"root\" of the graph always has gradient of 1\n",
    "    dedc,dedd=e.grad_fn(torch.tensor(1.))\n",
    "    print(\"gradient of e wrt to c is={}, wrt to d={}\".format(dedc,dedd))\n",
    "    #gradient functions of C and D\n",
    "    CgradFn=e.grad_fn.next_functions[0][0]\n",
    "    DgradFn=e.grad_fn.next_functions[1][0]\n",
    "    # apply to the last values\n",
    "    deda,dedb=CgradFn(dedc)\n",
    "    dedloga,dedlogb=DgradFn(dedd)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contribution of c branch to grad of a=2.0, to grad of b=2.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "      \n",
    "    # the \"C\" branch ends and accumulates in .grad\n",
    "    accA1=CgradFn.next_functions[0][0]\n",
    "    accB1=CgradFn.next_functions[1][0]\n",
    "    accA1(deda)\n",
    "    accB1(dedb)\n",
    "    print(\"contribution of c branch to grad of a={}, to grad of b={}\".format(a.grad,b.grad))\n",
    "    # the \"D\" branch has unamed nodes, loga and logb\n",
    "    LogAgradFn=DgradFn.next_functions[0][0]\n",
    "    LogBgradFn=DgradFn.next_functions[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6562) tensor(4.1640)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #apply to the last values\n",
    "    deda=LogAgradFn(dedloga)\n",
    "    dedb=LogBgradFn(dedlogb)\n",
    "    # the \"D\" branch ends and accumulates in .grad\n",
    "    accA=LogAgradFn.next_functions[0][0]\n",
    "    accA(deda)\n",
    "    accB=LogBgradFn.next_functions[0][0]\n",
    "    accB(dedb)\n",
    "    print(a.grad,b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rather than perform all the above operations manually, we can write a recursive function to go over all the nodes in the graph and computes the grads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def preorder(grad_fn,input,debug=False):\n",
    "    vals=grad_fn(input)\n",
    "    if debug:\n",
    "        print(grad_fn,input)\n",
    "    if isinstance(vals,tuple):\n",
    "        for (f,idx),val in zip(grad_fn.next_functions,vals):\n",
    "            preorder(f,val,debug)\n",
    "    else:\n",
    "        # in this example the \"log(a)\" and \"log(b)\" return a single output\n",
    "        # see slides page 14\n",
    "        if debug:\n",
    "            print(f\"single return {grad_fn.next_functions[0][0]}\")\n",
    "        preorder(grad_fn.next_functions[0][0],vals,debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a.grad,b.grad=None,None\n",
    "    preorder(e.grad_fn,torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6562) tensor(4.1640)\n"
     ]
    }
   ],
   "source": [
    "print(a.grad,b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x7fe8a2ddc3d0> tensor(1.)\n",
      "<AddBackward0 object at 0x7fe8a2d7d6c0> tensor(2.)\n",
      "<AccumulateGrad object at 0x7fe8a2d7d510> tensor(2.)\n",
      "<AccumulateGrad object at 0x7fe8a2ddd840> tensor(2.)\n",
      "<MulBackward0 object at 0x7fe8a2d7df60> tensor(6.)\n",
      "<Log2Backward0 object at 0x7fe8a2d3e740> tensor(12.)\n",
      "single return <AccumulateGrad object at 0x7fe8a2d7d510>\n",
      "<AccumulateGrad object at 0x7fe8a2d7d510> tensor(8.6562)\n",
      "<Log2Backward0 object at 0x7fe8a2d3ec80> tensor(6.)\n",
      "single return <AccumulateGrad object at 0x7fe8a2ddd840>\n",
      "<AccumulateGrad object at 0x7fe8a2ddd840> tensor(2.1640)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    a.grad,b.grad=None,None\n",
    "    preorder(e.grad_fn,torch.tensor(1.),debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In fact this is exactly how the ```torchviz``` package works (with more bells and whistles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchviz\n",
    "except ModuleNotFoundError:\n",
    "    %pip install torchviz\n",
    "    import torchviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"323pt\" height=\"326pt\"\n",
       " viewBox=\"0.00 0.00 323.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 319,-322 319,4 -4,4\"/>\n",
       "<!-- 140636939963360 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140636939963360</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"147.5,-31 93.5,-31 93.5,0 147.5,0 147.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140637026854480 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140637026854480</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"165,-86 76,-86 76,-67 165,-67 165,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140637026854480&#45;&gt;140636939963360 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140637026854480&#45;&gt;140636939963360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.5,-66.79C120.5,-60.07 120.5,-50.4 120.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124,-41.19 120.5,-31.19 117,-41.19 124,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140637147157488 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140637147157488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-196 113,-196 113,-177 202,-177 202,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140637147157488&#45;&gt;140637026854480 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140637147157488&#45;&gt;140637026854480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.95,-176.82C151.29,-164.54 144.26,-141.43 137.5,-122 134.47,-113.31 130.87,-103.77 127.76,-95.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.96,-94.33 124.04,-86.31 124.44,-96.9 130.96,-94.33\"/>\n",
       "</g>\n",
       "<!-- 140637027961488 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140637027961488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-251 47,-251 47,-232 148,-232 148,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140637027961488&#45;&gt;140637147157488 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140637027961488&#45;&gt;140637147157488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.14,-231.98C116.01,-224.15 129.37,-212.34 140.11,-202.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.51,-205.41 147.68,-196.17 137.87,-200.17 142.51,-205.41\"/>\n",
       "</g>\n",
       "<!-- 140637148092048 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140637148092048</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 0,-196 0,-177 95,-177 95,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">Log2Backward0</text>\n",
       "</g>\n",
       "<!-- 140637027961488&#45;&gt;140637148092048 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140637027961488&#45;&gt;140637148092048</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.24,-231.75C82.04,-224.11 71.39,-212.82 62.65,-203.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.01,-200.96 55.6,-196.09 59.92,-205.76 65.01,-200.96\"/>\n",
       "</g>\n",
       "<!-- 140636937768464 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140636937768464</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"124.5,-318 70.5,-318 70.5,-287 124.5,-287 124.5,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140636937768464&#45;&gt;140637027961488 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140636937768464&#45;&gt;140637027961488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.5,-286.92C97.5,-279.22 97.5,-269.69 97.5,-261.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101,-261.25 97.5,-251.25 94,-261.25 101,-261.25\"/>\n",
       "</g>\n",
       "<!-- 140637149034192 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140637149034192</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"292,-251 191,-251 191,-232 292,-232 292,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140637149034192&#45;&gt;140637147157488 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140637149034192&#45;&gt;140637147157488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M228,-231.98C215.1,-223.84 195.4,-211.41 180.1,-201.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.57,-198.55 171.24,-196.17 177.83,-204.47 181.57,-198.55\"/>\n",
       "</g>\n",
       "<!-- 140637141586112 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140637141586112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-196 220,-196 220,-177 315,-177 315,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">Log2Backward0</text>\n",
       "</g>\n",
       "<!-- 140637149034192&#45;&gt;140637141586112 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140637149034192&#45;&gt;140637141586112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M245.79,-231.75C249.31,-224.57 254.41,-214.18 258.78,-205.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.02,-206.61 263.29,-196.09 255.74,-203.53 262.02,-206.61\"/>\n",
       "</g>\n",
       "<!-- 140636937768624 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140636937768624</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"268.5,-318 214.5,-318 214.5,-287 268.5,-287 268.5,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140636937768624&#45;&gt;140637149034192 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140636937768624&#45;&gt;140637149034192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.5,-286.92C241.5,-279.22 241.5,-269.69 241.5,-261.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245,-261.25 241.5,-251.25 238,-261.25 245,-261.25\"/>\n",
       "</g>\n",
       "<!-- 140637149301440 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140637149301440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"129,-141 40,-141 40,-122 129,-122 129,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140637149301440&#45;&gt;140637026854480 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140637149301440&#45;&gt;140637026854480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.44,-121.75C95.48,-114.34 102.84,-103.5 109.01,-94.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.94,-96.33 114.67,-86.09 106.15,-92.39 111.94,-96.33\"/>\n",
       "</g>\n",
       "<!-- 140637148092048&#45;&gt;140637149301440 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140637148092048&#45;&gt;140637149301440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.61,-176.75C58.78,-169.34 66.35,-158.5 72.69,-149.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.65,-151.29 78.5,-141.09 69.91,-147.29 75.65,-151.29\"/>\n",
       "</g>\n",
       "<!-- 140637141586112&#45;&gt;140637149301440 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140637141586112&#45;&gt;140637149301440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.1,-176.98C207.11,-168.01 158.12,-153.82 123.83,-143.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.71,-140.5 114.13,-141.08 122.76,-147.23 124.71,-140.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fe8a2d7e750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(4.,requires_grad=True)\n",
    "c=a+b\n",
    "d=torch.log2(a)*torch.log2(b)\n",
    "e=c*d\n",
    "torchviz.make_dot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "pytorch2.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
